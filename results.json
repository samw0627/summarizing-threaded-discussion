[
  {
    "cluster": 0,
    "theme": "Minimizing Cognitive Offloading",
    "statements": {
      "statements": [
        {
          "statement": "Cognitive offloading leads to ignorance and dullness.",
          "excerpts": [
            "if you're always cognitive offloading, you won't develop knowledge and insights",
            "a person that eschews the work to create that interconnected web of knowledge is by contrast... ignorant, boring and dull"
          ]
        },
        {
          "statement": "Cultivating knowledge enhances our conversations and understanding.",
          "excerpts": [
            "that interconnected web of information makes a person knowledgeable, interesting and insightful",
            "you gotta know a few things so that you can think about those things and connect other things you might know"
          ]
        },
        {
          "statement": "Speed of information access is crucial for knowledge retention.",
          "excerpts": [
            "having it in your brain gives you the greatest speed and access to it",
            "Speed of information access is important"
          ]
        }
      ],
      "comments": [
        {
          "comment_id": "miz8fbp",
          "comment": "How to tell a person that engages heavily in cognitive offloading!\n\nSeriously though, if you're always cognitive offloading, you won't develop knowledge and insights that helps to inform your views and reactions to the world properly.\n\nIt's like been in a conversation and knowing that you could look up the location of paris, tokyo and their surrounding cities... and then not having the opportunity to do so without interrupting that conversation.\n\nOr worst yet, you don't even know what paris and tokyo are, and you don't know that there are surrounding cities - so you don't even understand the conversation at hand.\n\nIn other words, you gotta know a few things so that you can think about those things and connect other things you might know to those things - that interconnected web of information makes a person knowledgeable, interesting and insightful.\n\nA person that eschews the work to create that interconnected web of knowledge is by contrast... ignorant, boring and dull.\n\nSpeed of information access is important, and having it in your brain gives you the greatest speed and access to it.\n\nSomething more simple like time or car speed can be offloaded to external mechanisms - especially when the cost of looking it up is small, it's reliable, and the cost of maintaining it cognitively, accurately is high."
        }
      ]
    }
  },
  {
    "cluster": 1,
    "theme": "\"Decline of Critical Thinking Skills\"",
    "statements": {
      "statements": [
        {
          "statement": "AI usage is hindering critical thinking skills among students, leading to slower academic progress.",
          "excerpts": [
            "Oh, definitely. But it's getting worse. I'm a teacher at a university of applied sciences, and I've noticed a sharp decline in my students' problem solving and critical thinking skills.",
            "Students can regurgitate knowledge without a problem, but applying it in new situations or contexts.. That's a no go."
          ]
        },
        {
          "statement": "The dependency on AI tools reflects underdeveloped critical thinking abilities in users.",
          "excerpts": [
            "I think this is for people who use it as a crutch and can\u2019t get much done without it.",
            "But maybe that over reliance is caused by underdeveloped critical thinking skills and not vice versa."
          ]
        },
        {
          "statement": "Cognitive offloading through AI compromises essential reasoning abilities.",
          "excerpts": [
            "This has a direct impact on our basic reasoning and decision making capabilities.",
            "Kind of like having a robot servant that carries your luggage, you won't develop your own muscles because you're not carrying the weight yourself."
          ]
        },
        {
          "statement": "Reliance on AI tools leads to a false sense of confidence in knowledge recall.",
          "excerpts": [
            "We always have phones on us so memorizing numbers is unnecessary, but then we are often over confident on our recall when it is necessary.",
            "A lot of students are given calculators so early that they never fully develop basic arithmetic skills."
          ]
        },
        {
          "statement": "AI can perform complex tasks, diminishing the need for critical thought in users.",
          "excerpts": [
            "Over reliance on AI can weaken critical thinking to a greater degree since it can do complex tasks and the thinking for you.",
            "AI tools may weaken critical thinking skills by encouraging cognitive offloading."
          ]
        },
        {
          "statement": "Trust in AI can lead to a dangerous level of cognitive disengagement.",
          "excerpts": [
            "Saving energy isn\u2019t bad, it\u2019s about whether we consciously reinvest that energy.",
            "The difference here is that what's being offloaded is far more fundamental than keeping time."
          ]
        },
        {
          "statement": "Educational strategies must evolve to counterbalance the effects of AI on critical thinking.",
          "excerpts": [
            "This study contributes to the growing discourse on AI\u2019s cognitive implications, offering practical recommendations for mitigating its adverse effects on critical thinking.",
            "We\u2019ve found a way to train students to think critically while still allowing the use of AI."
          ]
        },
        {
          "statement": "The AI debate reveals deep concerns about cognitive development and decision-making.",
          "excerpts": [
            "Even if you were to feed it your every thought, and it were fully up to the task of parsing through it for you, there's still a crucial disconnect.",
            "What \u201ccognitive offloading\u201d does is instead of doing those calculations, that problem solving in your mind you make AI solve it."
          ]
        }
      ],
      "comments": [
        {
          "comment_id": "mizsb7d",
          "comment": "Oh, definitely. But it's getting worse. I'm a teacher at a university of applied sciences, and I've noticed a sharp decline in my students' problem solving and critical thinking skills. Students can regurgitate knowledge without a problem, but applying it in new situations or contexts.. That's a no go. And that means that they're progressing much, much slower than my previous cohorts of students. Thankfully, while it took us a while to adapt, but now we've found a way to train students to think critically while still allowing the use of AI. However, this has made our educational track a lot more difficult for some students who, previously, might still have eked by just by sheer force of will."
        },
        {
          "comment_id": "mj16ieu",
          "comment": "How do you make them think critically while using AI?"
        },
        {
          "comment_id": "miyknzt",
          "comment": "I\u2019ve linked to the news release in the post above. In this comment, for those interested, here\u2019s the link to the peer reviewed journal article: https://www.mdpi.com/2075-4698/15/1/6 Abstract The proliferation of artificial intelligence (AI) tools has transformed numerous aspects of daily life, yet its impact on critical thinking remains underexplored. This study investigates the relationship between AI tool usage and critical thinking skills, focusing on cognitive offloading as a mediating factor. Utilising a mixed-method approach, we conducted surveys and in-depth interviews with 666 participants across diverse age groups and educational backgrounds. Quantitative data were analysed using ANOVA and correlation analysis, while qualitative insights were obtained through thematic analysis of interview transcripts. The findings revealed a significant negative correlation between frequent AI tool usage and critical thinking abilities, mediated by increased cognitive offloading. Younger participants exhibited higher dependence on AI tools and lower critical thinking scores compared to older participants. Furthermore, higher educational attainment was associated with better critical thinking skills, regardless of AI usage. These results highlight the potential cognitive costs of AI tool reliance, emphasising the need for educational strategies to promote critical engagement with AI technologies. This study contributes to the growing discourse on AI\u2019s cognitive implications, offering practical recommendations for mitigating its adverse effects on critical thinking. The findings underscore the importance of fostering critical thinking in an AI-driven world, making this research essential reading for educators, policymakers, and technologists."
        },
        {
          "comment_id": "miz0sza",
          "comment": "\"cognitive offloading\" is just scientific gibberish for the concept of trust right ? Isn't the point of trust to save mental energy ? In that sense what is different with AI than all the others tools we use everyday ? I trust my watch, I trust the speed throttle of my car, is it bad ? Saving mental energy doesn't make you braindead. This energy is always reallocated to others tasks."
        },
        {
          "comment_id": "mj32qnt",
          "comment": "It depends on the topic. AI is sometimes not strong enough for some technical topics. And about subjective/political/societal questions, it is supposed to share the different views on a same subject, to objectify its statements. But in reality, its answers have an ethnocentered bias and it is more often sharing common sense than a serious analysis on the topic. Talking about Wikip\u00e9dia or AI, the problem is not with the tool. The problem is some users don't know well the limitations of the tool. And in the case of AI use, they could think a well-shaped answer is a definitive truth, when it's sometimes controversial or inaccurate, but not presented this way by the AI."
        },
        {
          "comment_id": "mj1e9ka",
          "comment": "The difference here is that what's being offloaded is far more fundamental than keeping time, or even something like math or navigation. This has a direct impact on our basic reasoning and decision making capabilities. And no, it'd be more accurate to say that cognitive offloading refers to the *byproduct* of such trust. Your brain quite literally becomes less capable at that task, as it subconsciously determines it isn't necessary. Whatever your thoughts on AI, this should be concerning to everyone. Even if you were to feed it your every thought, and it were fully up to the task of parsing through it for you, there's still a crucial disconnect between its thoughts and your own."
        },
        {
          "comment_id": "mj1t2v8",
          "comment": "Using the word \"trust\" is weird to me. I think it's better to look at this from a neurological perspective. When you do something neurons are formed in your brain. Be it something mental, such as math, or physical, such as sports. You practice those things and your neurons get stronger. In the case of sports your muscles get stronger but also neurons that control those muscles, and through that your coordination. In the case of math the repeated practice of different equations strengthens the neurons responsible, which results in faster recognition of problems and their solutions. So what \"cognitive offloading\" does is instead of doing those calculations, that problem solving in your mind (and thus strengthening your problem solving neurons) you make AI solve it, and thus you don't develop and strengthen those neurons. Kind of like having a robot servant that carries your luggage, you won't develop your own muscles because you're not carrying the weight yourself."
        },
        {
          "comment_id": "miz370j",
          "comment": "I agree wirh you. Cognitive offloading at its core is a form of trust. We\u2019ve always relied on tools to save mental effort from watches to notebooks. But maybe the difference with AI isn\u2019t the offloading itself but how much of the decision making we\u2019re comfortable outsourcing without realizing it. Saving energy isn\u2019t bad, it\u2019s about whether we consciously reinvest that energy or if the tool quietly shapes our thinking patterns without us noticing."
        },
        {
          "comment_id": "mj0cp3r",
          "comment": "The issue is contextual, it causes an issue when we want to recall the information or mental skill that is being offloaded. We always have phones on us so memorizing numbers is unnecessary, but then we are often over confident on our recall when it is necessary. I have students who will argue about taking notes because they can take pictures of the board with their phone.  A lot of students are given calculators so early that they never fully develop basic arithmetic skills and ends up increases the cognitive load in math as the progress through harder classes."
        },
        {
          "comment_id": "miyyks3",
          "comment": "Uhh Google can also weaken critical thinking"
        },
        {
          "comment_id": "mj1zc3s",
          "comment": "Most tech, including calculators, spreadsheets, online maps, etc., contributes to cognitive offloading. Google searches gives you information (and sometimes you could think of the info yourself), but generally you do something with it after you get the result. But over reliance on AI can weaken critical thinking to a greater degree since it can do complex tasks and the thinking for you, if you let it."
        },
        {
          "comment_id": "miz2nqu",
          "comment": "I think this is for people who use it as a crutch and can\u2019t get much done without it. But maybe that over reliance is caused by underdeveloped critical thinking skills and not vice versa. I also use it to save time on emails but I\u2019ll eat paint before calling myself an \u201cAI artist\u201d or whatever lol"
        },
        {
          "comment_id": "mj7tqk4",
          "comment": "Glancing over the paper very quickly, this study was poorly conducted. Subjects\u2019 use of AI tools was not randomly assigned. The researchers basically conducted a survey finding a correlation between use of AI and cognitive abilities. But, a simpler explanation for their finding is this: people with stronger cognitive abilities are probably just less reliant on AI in the first place. Am I missing something here? The qualitative review may go some ways toward their explanation, but still, I don\u2019t find that very convincing. It\u2019s easy for people to fall into the trap of assuming AI makes them less critical thinkers. That\u2019s certainly more palatable than accepting you weren\u2019t a critical thinker in the first place."
        },
        {
          "comment_id": "mj09pkh",
          "comment": "Is it me or is \"cognitive offloading\" kind of an odd term? Like nobody talks like that about books, Google, the internet, watching a YouTube video, asking a friend/teacher, etc"
        },
        {
          "comment_id": "mj31xm2",
          "comment": "Couldn\u2019t this be fixed with a simple prompt addition? \u201c<AI tool>, please answer in a way that ensures I am maintaining optimum cognitive engagement. I want to minimise the amount of cognitive offloading I pass to you whilst optimising my engagement with you.\u201d"
        }
      ]
    }
  },
  {
    "cluster": 2,
    "theme": "\"Enhancing Critical Thinking with AI\"",
    "statements": {
      "statements": [
        {
          "statement": "Memorizing information does not lead to true mastery, especially in cybersecurity.",
          "excerpts": [
            "Oh, entirely true. And learning just to recite stuff by heart isn't really mastering the topic."
          ]
        },
        {
          "statement": "Relying too heavily on AI tools undermines foundational critical thinking skills.",
          "excerpts": [
            "The moment students skip out on the first critical thinking exercises by resorting to Chatgpt, they avoid laying the foundations."
          ]
        },
        {
          "statement": "Innovative assessments can significantly enhance critical thinking and engagement.",
          "excerpts": [
            "We've avoided this problem by reworking all our tests into critical thinking applications."
          ]
        },
        {
          "statement": "AI can enhance learning but must be used with intent to foster critical thinking.",
          "excerpts": [
            "AI can be a very useful tool for learning and understanding, but it definitely needs to be used with the intent to do so critically."
          ]
        },
        {
          "statement": "Overreliance on AI for writing diminishes student engagement with material.",
          "excerpts": [
            "...using AI to do the reading and then do the bulk of the writing... can often completely remove the student from the material entirely."
          ]
        },
        {
          "statement": "AI is effective for critical thinking when used actively, but harmful when used passively.",
          "excerpts": [
            "It's fuck awful as a passive tool I think. Both in quality and in impact on you as a thinker."
          ]
        },
        {
          "statement": "AI's impact on cognitive thinking has been surprisingly positive.",
          "excerpts": [
            "I still believe AI has created a more positive effect than negative effects."
          ]
        },
        {
          "statement": "Using AI for critical thinking can provide engaging and enjoyable experiences.",
          "excerpts": [
            "the primary purpose I use AI for is literally to do critical thinking for fun, it's the perfect tool for that."
          ]
        },
        {
          "statement": "There is a crucial difference between access to knowledge and the synthesis of it.",
          "excerpts": [
            "While all the things you\u2019ve mentioned help the former, AI actively shapes the latter."
          ]
        }
      ],
      "comments": [
        {
          "comment_id": "mizzxz3",
          "comment": "Oh, entirely true. And learning just to recite stuff by heart isn't really mastering the topic. I mean, then you're just stuck at the lower two levels of Bloom's taxonomy. In my specific case, we help students develop their cyber security knowledge, so then it's more relevant. Critical thinking and analysis is part of the core of our field. The moment students skip out on the first critical thinking exercises by resorting to Chatgpt, they avoid laying the foundations that they need over the next four years. We've avoided this problem by reworking all our tests into critical thinking applications. So they do verbal presentations, pressure cooker sessions where they need to apply their skills in new contexts, timed capture the flags on physical devices without access to the Internet, verbal assessments, they do classroom exercises where they give each other feedback and they brainstorm ideas together... It's a fun solution."
        },
        {
          "comment_id": "mj14ag6",
          "comment": "> we've found a way to train students to think critically while still allowing the use of AI. Interesting - could you expand on that."
        },
        {
          "comment_id": "mjy883b",
          "comment": "I work with graduate school interns\u2026teaching them critical thinking takes alot of critical thinking \ud83d\ude05\ud83e\udd17. Would love to know your method for effectively training students\u2019 critical thinking skills while still integrating AI?"
        },
        {
          "comment_id": "mj1cbuy",
          "comment": "I mentioned it in a different comment here. Our rubric assesses critical thinking, so our testing methods put students in a situation where they have to apply those skills. For example, for a written report, they might use AI to write the report, but the written report is an entry requirement for a verbal assessment. Once they clear that hurdle, they have to explain their reasoning for certain choices in the report, or explain logical structures. If they can do that, we ask them how designs or conclusions would change if certain conditions or circumstances would change. We ask them about conflicting conditions and guidelines, how they would navigate that, whether that would lead to complications in this situation... We do the same for coding. Sure, you might use AI to write the code, but then I manually change the data structures they use as input. Someone who wrote the code should, realistically, be able to adjust their entire program based my cues. Or I ask them to add a new method to their class, using specific inputs and outputs. We ask them why they used certain code structures, what the impact is on the functioning of the program, that sort of thing. So, long story short, they might use AI, but we don't assess students on the products they deliver, we assess them on their ability to apply the skills they needed to create those products in new situations."
        },
        {
          "comment_id": "mj4sqbw",
          "comment": "Yeah I feel like asking the AI to put the question into a scenario or case study can help with this, given the context. Immediately (and/or soon after learning) and repeatedly applying knowledge in the same 'session' is a known way to reinforce it. AI gets a bad go but appropriately utilising it to the fullest can make it extremely powerful in a learning context."
        },
        {
          "comment_id": "mj0ddmq",
          "comment": "I think it\u2019s quite different. Both with books and the internet you are still reading the information, and in turn writing your thesis / essay or what have you. In this case people are using AI to do the reading and then do the bulk of the writing. This can often completely remove the student from the material entirely, whereas the internet did not do that. The internet just brought the information from the library into your bedroom. It outsourced the walking to the library and the using of the dewey decimal system. People might not be so great at finding their material in a library, but can still analyze the information and discuss it in a comprehensible way. If AI does your research and writes your paper, how do you then discuss the paper in a comprehensible way? I would liken it to the damage on a persons education by plagiarism, as that is a more apt comparison. Students are removing themselves from the material entirely. Likening it to the library/ internet is not apples to apples at all. The internet made finding information more efficient for learning as it eliminates or minimizes wasted time looking for information that can then be spent analyzing the information. AI learns instead of the student."
        },
        {
          "comment_id": "miz67x9",
          "comment": "AI can be a very useful tool for learning and understanding, but it definitely needs to be used with the intent to do so critically. I love using it to stress test my own ideas and find flaws in my thinking or explanations. I love drawing analogies to check my understanding and seeing if it can get back to the concept I'm explaining by feeding it my analogues or 'models' of a concept I want to discuss. And whenever it gives me 'an answer' or knowledge I didn't know before, I always stress test that in reverse.starting a new instance and seeing if it understands it's own idea. Sometimes it'll go 'never heard of that' sometimes it confirms it and I can find more literature on it. But it's only a good tool if used actively. It's fuck awful as a passive tool I think. Both in quality and in impact on you as a thinker."
        },
        {
          "comment_id": "mjo6es6",
          "comment": "Not surprising, but we could already see that with the prevalence of nighttime news casting. People have been told how to think for almost 100 years. Radio was almost as bad before that. Print was somewhat ok, but still full of issues. Honestly? I think AI is useful for helping explain concepts I just don't understand. And for helping me edit emails and cover letters because I suck at setting tone."
        },
        {
          "comment_id": "miz4s74",
          "comment": "It's been almost two years since Chatgpt was introduced to the world. I'm glad there's studies being done on how AI has effected cognitive thinking. I still believe AI has created a more positive effect than negative effects. It would be interesting to see how AI therapy compares to human to human therapy."
        },
        {
          "comment_id": "mizgq1n",
          "comment": "Bruh, the primary purpose I use AI for is literally to do critical thinking for fun, it's the perfect tool for that. It engages with you while providing the exact pieces of information you need."
        },
        {
          "comment_id": "mj2gypc",
          "comment": "So basically, you can\u2019t see the difference between access to knowledge and synthesis thereof? While all the things you\u2019ve mentioned help the former, AI actively shapes latter, which is where active cognitive skills come in to play."
        }
      ]
    }
  },
  {
    "cluster": 3,
    "theme": "\"Trust and Responsibility in AI\"",
    "statements": {
      "statements": [
        {
          "statement": "Cognitive offloading requires critical thinking to avoid gullibility.",
          "excerpts": [
            "If 'cognitive offloading' is trust, then 'critical thinking' would be a measure of gullibility.",
            "But do you trust everything you read on the Internet? Because there's a Nigerian prince trying to give you money."
          ]
        },
        {
          "statement": "Relying on AI can lead to serious logical errors in coding.",
          "excerpts": [
            "I\u2019ve also noticed that whenever I do this for any extended period of time, I start making some seriously egregious logical errors I wouldn\u2019t normally make.",
            "Stupid redundant code, silly mistakes, being confused by stuff I shouldn\u2019t be confused by."
          ]
        },
        {
          "statement": "AI misuse reflects a troubling laziness in society.",
          "excerpts": [
            "way too many people see it as an excuse to be lazy, have you seen all those FB ads about it allowing you to cheat in school undetected.",
            "AI needs severe restrictions and regulations."
          ]
        },
        {
          "statement": "The flaws of AI tools may parallel the issues in some leadership roles.",
          "excerpts": [
            "If this is true for AI tools, I wonder if it's the same for certain types of leadership roles."
          ]
        }
      ],
      "comments": [
        {
          "comment_id": "mizkpeh",
          "comment": "If 'cognitive offloading' is trust, then 'critical thinking' would be a measure of gullibility. You probably trust your watch and car because you understand a degree of how they work, know that they've been through quality testing, and know others find them reliable. But do you trust everything you read on the Internet? Because there's a Nigerian prince trying to give you money, and his words may be included in your AI's training dataset."
        },
        {
          "comment_id": "mizbpmt",
          "comment": "I feel that when I\u2019m coding tbh. I\u2019m shit at it. Always have been. Only need to do it every once in a while. So using AI to help with the smaller things or when I\u2019m stumped/have a very specific problem with little documentation, I can crawl my way through it. But I\u2019ve also noticed that whenever I do this for any extended period of time, I start making some seriously egregious logical errors I wouldn\u2019t normally make. Stupid redundant code, silly mistakes, being confused by stuff I shouldn\u2019t be confused by. So anecdotally, this rings true."
        },
        {
          "comment_id": "mizo9q1",
          "comment": "If this is true for AI tools, I wonder if it's the same for certain types of leadership roles, to the extent that it might be a mechanism that leads to states like hubris."
        },
        {
          "comment_id": "mjevqv0",
          "comment": "Honestly I wouldn't be surprised if it was true, way too many people see it as an excuse to be lazy, have you seen all those FB ads about it allowing you to cheat in school undetected in an attempt to get students to buy/subscribe to their services, or the other ones that say you can publish thousands of books every month all you have to do is let their AI program do all the work? AI needs severe restrictions and regulations."
        }
      ]
    }
  },
  {
    "cluster": 4,
    "theme": "\"Practical Learning in Mathematics\"",
    "statements": {
      "statements": [
        {
          "statement": "High cognitive load stifles true understanding in mathematics education.",
          "excerpts": [
            "the demands of the huge spike in information processing",
            "the cognitive load of that schedule, of the world going on around us"
          ]
        },
        {
          "statement": "Practical submissions enhance learning and retention in complex subjects.",
          "excerpts": [
            "the year I was finally allowed to submit code instead of line by line proofs",
            "are the ones where I wasn\u2019t forced to do tons of make work"
          ]
        },
        {
          "statement": "Traditional methods often lead to stress and hinder actual comprehension.",
          "excerpts": [
            "it really was just a blur of stress",
            "doing just enough of what I was told so I wouldn\u2019t fail"
          ]
        }
      ],
      "comments": [
        {
          "comment_id": "mj2xbfn",
          "comment": "That is a fair point to an extent. I think if the demands of the huge spike in information processing required, just to navigate day to day, weren\u2019t so high, it would be a stronger argument. I went through an undergraduate mathematics degree, and the classes I did best in and remember the most from, are the ones where I wasn\u2019t forced to do tons of make work. The year I was finally allowed to submit code instead of line by line proofs, was when I was able to finally start understanding it. Was it because the fundamentals had been beaten into me first? I know that\u2019s the common argument. But let me tell you that the cognitive load of that schedule, of the world going on around us, everything; it really was just a blur of stress, hand cramps from being forced to manually write out everything, and doing just enough of what I was told so I wouldn\u2019t fail, so I\u2019d have enough time to move to the next thing that was on fire."
        }
      ]
    }
  }
]